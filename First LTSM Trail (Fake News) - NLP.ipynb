{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import re\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "\n",
    "import nltk\n",
    "import nltk as nlp\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('no_stopwords_combined.csv')\n",
    "test = pd.read_csv('testnostopwords.csv')\n",
    "\n",
    "train_copy = train.copy(deep = True)\n",
    "test_copy = test.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ramaphosa's ANC election win lifts South Afric...</td>\n",
       "      <td>johannesburg reuters south african banking sto...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>December 19, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VIGILANTE PIRATES INTERCEDE Where Government F...</td>\n",
       "      <td>like soldiers oden vigilante group reported fe...</td>\n",
       "      <td>Government News</td>\n",
       "      <td>Apr 1, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>SICK! DEMOCRAT ORGANIZER, Mayor DeBlasio Emplo...</td>\n",
       "      <td>last week huma abedin husband anthony weiner w...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>May 28, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "2           2             2   \n",
       "\n",
       "                                               title  \\\n",
       "0  Ramaphosa's ANC election win lifts South Afric...   \n",
       "1  VIGILANTE PIRATES INTERCEDE Where Government F...   \n",
       "2  SICK! DEMOCRAT ORGANIZER, Mayor DeBlasio Emplo...   \n",
       "\n",
       "                                                text          subject  \\\n",
       "0  johannesburg reuters south african banking sto...        worldnews   \n",
       "1  like soldiers oden vigilante group reported fe...  Government News   \n",
       "2  last week huma abedin husband anthony weiner w...        left-news   \n",
       "\n",
       "                 date  target  \n",
       "0  December 19, 2017        1  \n",
       "1         Apr 1, 2016       0  \n",
       "2        May 28, 2017       0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        0\n",
       "Unnamed: 0.1      0\n",
       "title             0\n",
       "text            718\n",
       "subject           0\n",
       "date              0\n",
       "target            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starter Code EDA Result\n",
    "\n",
    "- It is better to use the NaN rows, as all of them correspond to fake news\n",
    "- One of the local rows in the dataset with null text is however labelled \"true news\"\n",
    "- Pipeline doesn;t work with NaN values, so we'll replace NaN by 'Empty' string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_copy.dropna(subset = ['text'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy.fillna('Empty', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 52.49%\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', LogisticRegression())])\n",
    "\n",
    "model = pipe.fit(train_copy['text'],train_copy['target'])\n",
    "pred = model.predict(test_copy['text'])\n",
    "\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(test_copy['target'],\n",
    "                                                  pred)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[131 247]\n",
      " [135 291]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_copy['target'],\n",
    "                      pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 50.62%\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', LinearSVC())])\n",
    "\n",
    "model = pipe.fit(train_copy['text'],train_copy['target'])\n",
    "pred = model.predict(test_copy['text'])\n",
    "\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(test_copy['target'],\n",
    "                                                  pred)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[155 223]\n",
      " [174 252]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_copy['target'],\n",
    "                      pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 50.62%\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', LinearSVC())])\n",
    "\n",
    "model = pipe.fit(train_copy['text'],train_copy['target'])\n",
    "pred = model.predict(test_copy['text'])\n",
    "\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(test_copy['target'],\n",
    "                                                  pred)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[155 223]\n",
      " [174 252]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_copy['target'],\n",
    "                      pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 48.51%\n",
      "[[330  48]\n",
      " [366  60]]\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', GradientBoostingClassifier(loss = 'deviance',\n",
    "                                                   learning_rate = 0.01,\n",
    "                                                   n_estimators = 10,\n",
    "                                                   max_depth = 5,\n",
    "                                                   random_state=42))])\n",
    "\n",
    "model = pipe.fit(train_copy['text'],train_copy['target'])\n",
    "pred = model.predict(test_copy['text'])\n",
    "\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(test_copy['target'],\n",
    "                                                  pred)*100,2)))\n",
    "\n",
    "print(confusion_matrix(test_copy['target'],\n",
    "                      pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 48.51%\n",
      "[[330  48]\n",
      " [366  60]]\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', XGBClassifier(loss = 'deviance',\n",
    "                                        learning_rate = 0.01,\n",
    "                                        n_estimators = 10,\n",
    "                                        max_depth = 5,\n",
    "                                        random_state=2020))])\n",
    "\n",
    "model = pipe.fit(train_copy['text'],train_copy['target'])\n",
    "pred = model.predict(test_copy['text'])\n",
    "\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(test_copy['target'],\n",
    "                                                  pred)*100,2)))\n",
    "\n",
    "print(confusion_matrix(test_copy['target'],\n",
    "                      pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 53.61%\n",
      "[[ 29 349]\n",
      " [ 24 402]]\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('model', RandomForestClassifier())])\n",
    "\n",
    "model = pipe.fit(train_copy['text'],train_copy['target'])\n",
    "pred = model.predict(test_copy['text'])\n",
    "\n",
    "print(\"accuracy: {}%\".format(round(accuracy_score(test_copy['target'],\n",
    "                                                  pred)*100,2)))\n",
    "\n",
    "print(confusion_matrix(test_copy['target'],\n",
    "                      pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM - Recurrent Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_copy['text']\n",
    "Y = train_copy['target']\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 500\n",
    "max_len = 75\n",
    "\n",
    "tok = Tokenizer(num_words = max_words)\n",
    "tok.fit_on_texts(X)\n",
    "\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences, maxlen = max_len)\n",
    "\n",
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n",
    "model = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = RMSprop(),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 75, 50)            25000     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 71,337\n",
      "Trainable params: 71,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35918 samples, validate on 8980 samples\n",
      "Epoch 1/10\n",
      "35918/35918 [==============================] - 11s 294us/step - loss: 0.0416 - accuracy: 0.9856 - val_loss: 0.1085 - val_accuracy: 0.9728\n",
      "Epoch 2/10\n",
      "35918/35918 [==============================] - 11s 302us/step - loss: 0.0384 - accuracy: 0.9867 - val_loss: 0.0751 - val_accuracy: 0.9785\n",
      "Epoch 3/10\n",
      "35918/35918 [==============================] - 10s 284us/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 0.0629 - val_accuracy: 0.9815\n",
      "Epoch 4/10\n",
      "35918/35918 [==============================] - 17s 461us/step - loss: 0.0330 - accuracy: 0.9892 - val_loss: 0.0727 - val_accuracy: 0.9806\n",
      "Epoch 5/10\n",
      "35918/35918 [==============================] - 15s 406us/step - loss: 0.0297 - accuracy: 0.9899 - val_loss: 0.0653 - val_accuracy: 0.9801\n",
      "Epoch 6/10\n",
      "35918/35918 [==============================] - 12s 331us/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.0768 - val_accuracy: 0.9722\n",
      "Epoch 7/10\n",
      "35918/35918 [==============================] - 14s 385us/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 0.0680 - val_accuracy: 0.9798\n",
      "Epoch 8/10\n",
      "35918/35918 [==============================] - 12s 331us/step - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.0796 - val_accuracy: 0.9712\n",
      "Epoch 9/10\n",
      "35918/35918 [==============================] - 15s 405us/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.0908 - val_accuracy: 0.9777\n",
      "Epoch 10/10\n",
      "35918/35918 [==============================] - 15s 406us/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.0922 - val_accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2430cf1a388>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix, Y, batch_size = 256, epochs = 10,\n",
    "         validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(test_copy['text'])\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences, \n",
    "                                               maxlen = max_len)\n",
    "\n",
    "accr = model.evaluate(test_sequences_matrix, test_copy['target'])\n",
    "print('Accuracy :{:0.2f}'.format(accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['text'][:20].str.len()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('gpu': conda)",
   "language": "python",
   "name": "python37764bitgpuconda08766899e99640f8bf22a5cda132f1fd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
